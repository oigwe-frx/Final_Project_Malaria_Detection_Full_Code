{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "HDM89XHyCxrA",
        "UC8-yLUUCcWh",
        "NqOnCq3FZ6JG",
        "_2cJN07Bbofx",
        "BrpS4Azamjs4",
        "8EFWVEUKoM1U",
        "ra-GUCjbLHGg",
        "Mhoug92KFWPa"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oigwe-frx/Final_Project_Malaria_Detection_Full_Code/blob/main/Final_Malaria_Detection_Full_Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Malaria Detection**"
      ],
      "metadata": {
        "id": "xbL3dHCsb6UT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCiPVBNbA0Wh"
      },
      "source": [
        "## <b>Problem Definition</b>\n",
        "\n",
        "### **The Context:**\n",
        "Malaria is a contagious disease caused by <i>Plasmodium parasites</i> transmitted by a parasite-carrying <i>Anopheles</i> mosquito. According to the World Health Organization's Annual Malaria Report (2023), despite global strides in providing preventative measures and interventional responses, more cases of malaria were reported in 2022 compared to 2019 [1].\n",
        "\n",
        "Almost 50% of the world’s population is in danger from malaria. In 2019, there were over 229 million reported cases and 400,000 deaths, with children under 5 years old being the most vulnerable. \"In 2022, there were an estimated 249 million malaria cases globally, exceeding the pre-pandemic level of 233 million in 2019 by 16 million cases\" [2]. In 2019, 400,000 malaria-related deaths were reported globally.\n",
        "\n",
        "According to the CDC, \"microscopic [blood] examination remains the “gold standard” for laboratory confirmation of malaria\" [3]. Traditional laboratory diagnosis of a malaria infection involves a series of steps that require trained professionals to examine blood samples under a microscope and identify the presence of <i>Plasmodium parasites</i>. According to medlineplus.gov, to obtain a definitive negative result from a microscopic test, \"blood samples are usually taken every 12-24 hours for a total of 3 sets of tests\" [4]. In addition to the 36-81 hours needed to perform the test, significant human effort must be invested. The efficacy of microscopic malaria diagnosis in a laboratory can vary depending on several factors, including the experience of the laboratory technician, the workload of the laboratory, and the complexity of the case.\n",
        "\n",
        "The application of deep learning algorithms in malaria detection offers a powerful and versatile tool for improving the accuracy, speed, and efficiency of diagnosis while reducing the reliance on human expertise. These benefits can lead to earlier treatment, better patient outcomes, and more effective management of malaria in regions where it is prevalent.\n",
        "\n",
        "***Citations***:<br/>\n",
        "[1]: \"Switzerland : WHOs Annual Malaria Report Spotlights the Growing Threat of Climate Change.\" MENA Report, vol. , no. , 2023, p. .<br/>\n",
        "[2]: \"Switzerland : WHOs Annual Malaria Report Spotlights the Growing Threat of Climate Change.\" MENA Report, vol. , no. , 2023, p. . <br/>\n",
        "[3]: Anjorin, Emmanuel T., et al. \"Overtreatment of Malaria in the Nigerian Healthcare Setting; Prescription Practice, Rationale and Consequences.\" The Pan African Medical Journal, 2023,  https://doi.org/10.11604/pamj.2023.45.111.31780. <br/>\n",
        "[4]: Malaria Tests: MedlinePlus Medical Test. https://medlineplus.gov/lab-tests/malaria-tests/ <br/>\n",
        "\n",
        "\n",
        "### **The Objectives:**\n",
        "\n",
        "The objective is to build an efficient computer vision model to detect malaria. The model will be trained to differentiate whether an image of a red blood cell is one that is infected with malaria (classify the cell as parasitized or uninfected).\n",
        "\n",
        "### **The Key Questions:**\n",
        "\n",
        "***Data Collection***:\n",
        "\n",
        "- What is the source of the dataset for training and testing the algorithm?\n",
        "- How large and diverse is the dataset?\n",
        "\n",
        "***Data Preprocessing***:\n",
        "\n",
        "- What techniques are required for image augmentation, normalization, and enhancement?\n",
        "\n",
        "***Model Architecture***:\n",
        "\n",
        "- What deep learning architecture should be chosen for the algorithm?\n",
        "- How many layers and neurons should the model have?\n",
        "\n",
        "***Hyperparameter Tuning***:\n",
        "\n",
        "- How should the training process be optimized to prevent overfitting or underfitting?\n",
        "\n",
        "***Class Imbalance***:\n",
        "\n",
        "- How can class imbalance issues be addressed if there are significant differences in the number of parasitized and uninfected samples?\n",
        "\n",
        "***Performance Metrics***:\n",
        "\n",
        "- What is the acceptable level of false positives or false negatives in malaria detection?\n",
        "\n",
        "***Real-time Processing***:\n",
        "\n",
        "- Can the deep learning algorithm be optimized for real-time or near-real-time processing of blood smear images?\n",
        "\n",
        "***Scalability and Generalization***:\n",
        "\n",
        "- Can the algorithm be generalized to different populations, regions, and healthcare settings?\n",
        "- How can the algorithm adapt to variations in image quality and conditions?\n",
        "\n",
        "### **The Problem Formulation:**\n",
        "Develop an automated deep learning-based system for the detection of malaria parasites in blood smear images to enhance the accuracy and efficiency of diagnosis, particularly in resource-constrained regions with limited access to skilled technicians and healthcare facilities.\n",
        "\n",
        "## <b>Data Description </b>\n",
        "\n",
        "There are a total of 24,958 training and 2,600 test images (colored) that have been taken from microscopic images. These images are of the following categories:<br>\n",
        "\n",
        "**Parasitized:** The parasitized cells contain the Plasmodium parasite which causes malaria.<br>\n",
        "**Uninfected:** The uninfected cells are free of the Plasmodium parasites.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDM89XHyCxrA"
      },
      "source": [
        "###<b> Mount the Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQi_degJC3dm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "c9e1ea86-5da7-4d98-aec1-3ebcfba71ecc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    127\u001b[0m   )\n\u001b[1;32m    128\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UC8-yLUUCcWh"
      },
      "source": [
        "### <b>Loading libraries</b>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Library for randomly selecting data points\n",
        "import random\n",
        "\n",
        "# Libraries for performing numerical computations\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Library for creating and showing plots\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Library to interact with the operating system\n",
        "import os\n",
        "\n",
        "# Open Source Computer Vision Library\n",
        "import cv2\n",
        "\n",
        "# TensorFlow modules\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import (\n",
        "    Dense, Conv2D, MaxPool2D, BatchNormalization, Dropout, Flatten, LeakyReLU\n",
        ")\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# scikit-learn modules\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "# Torchvision modules\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "# Zipfile\n",
        "import zipfile\n",
        "\n",
        "# Operating System Interface\n",
        "import os\n",
        "\n",
        "# Libraries for Image Padding\n",
        "from PIL import Image, ImageOps\n",
        "\n",
        "# Library to add progress bars to loops - tracking progress\n",
        "from tqdm import tqdm\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "metadata": {
        "id": "iixNDZWs1ZPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCqJk2XpCnJi"
      },
      "source": [
        "### <b>Let us load the data</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_syvBdMlDTsr"
      },
      "source": [
        "**Note:**\n",
        "- You must download the dataset from the link provided on Olympus and upload the same to your Google Drive. Then unzip the folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufMU62DICjLV"
      },
      "source": [
        "# Specify the path to the uploaded ZIP file\n",
        "zip_file_path = '/content/drive/MyDrive/cell_images.zip'\n",
        "\n",
        "# Unzip the file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IW3fDq7gF4Hw"
      },
      "source": [
        "The extracted folder has different folders for train and test data will contain the different sizes of images for parasitized and uninfected cells within the respective folder name.\n",
        "\n",
        "The size of all images must be the same and should be converted to 4D arrays so that they can be used as an input for the convolutional neural network. Also, we need to create the labels for both types of images to be able to train and test the model.\n",
        "\n",
        "Let's do the same for the training data first and then we will use the same code for the test data as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjK02uF1DXdW"
      },
      "source": [
        "# Define the path to dataset directory\n",
        "data_dir = '/content/cell_images'\n",
        "\n",
        "# Define the common size for all images\n",
        "image_size = (128, 128)\n",
        "\n",
        "# Initialize empty lists for images and labels\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "# Define the subfolders for training and testing\n",
        "subfolders = ['train', 'test']\n",
        "\n",
        "for subfolder in subfolders:\n",
        "    for folder_name in os.listdir(os.path.join(data_dir, subfolder)):\n",
        "        if folder_name == 'parasitized':\n",
        "            label = 1  #  Label 1 for infected images\n",
        "        elif folder_name == 'uninfected':\n",
        "            label = 0  #  Label 0 for uninfected images\n",
        "        else:\n",
        "            continue  # Skip other folders\n",
        "\n",
        "        folder_path = os.path.join(data_dir, subfolder, folder_name)\n",
        "\n",
        "        for filename in tqdm(os.listdir(folder_path)):\n",
        "            file_path = os.path.join(folder_path, filename)\n",
        "            try:\n",
        "                # Open and resize the image\n",
        "                img = Image.open(file_path)\n",
        "                img = img.resize(image_size)\n",
        "                img = np.array(img)\n",
        "\n",
        "                # Append the image and label to the lists\n",
        "                images.append(img)\n",
        "                labels.append(label)\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {file_path}: {str(e)}\")\n",
        "\n",
        "# Convert the lists to numpy arrays\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_rxFT9iH7pR"
      },
      "source": [
        "###<b> Check the shape of train and test images"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the shapes of the arrays (for verification)\n",
        "print(\"Training Images shape:\", X_train.shape)\n",
        "print(\"Testing Images shape:\", X_test.shape)"
      ],
      "metadata": {
        "id": "LA8HJmQp1hU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3AiiutGIEoy"
      },
      "source": [
        "###<b> Check the shape of train and test labels"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the shapes of the arrays (for verification)\n",
        "print(\"Training Labels shape:\", y_train.shape)\n",
        "print(\"Testing Labels shape:\", y_test.shape)"
      ],
      "metadata": {
        "id": "UJ_uvmT61rvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3gtgoubINVX"
      },
      "source": [
        "####<b> Observations and insights: _____ </b>\n",
        "\n",
        "  There are a total of 24,958 training and 2,600 test images\n",
        "  - Each image has a shape of (128, 128, 3), which means they are 128 pixels in width, 128 pixels in height, and have 3 color channels.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFUMkif7IjlO"
      },
      "source": [
        "### <b>Check the minimum and maximum range of pixel values for train and test images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gJbhCbMIswX"
      },
      "source": [
        "# Calculate the minimum and maximum pixel values for training images\n",
        "train_min_pixel = X_train.min()\n",
        "train_max_pixel = X_train.max()\n",
        "\n",
        "# Calculate the minimum and maximum pixel values for testing images\n",
        "test_min_pixel = X_test.min()\n",
        "test_max_pixel = X_test.max()\n",
        "\n",
        "# Print the minimum and maximum pixel values for training images\n",
        "print(\"Minimum pixel value for training images:\", train_min_pixel)\n",
        "print(\"Maximum pixel value for training images:\", train_max_pixel)\n",
        "\n",
        "# Print the minimum and maximum pixel values for testing images\n",
        "print(\"Minimum pixel value for testing images:\", test_min_pixel)\n",
        "print(\"Maximum pixel value for testing images:\", test_max_pixel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_T8WWuSpI6Ih"
      },
      "source": [
        "####<b> Observations and insights: _____ </b>\n",
        "\n",
        "Minimum pixel value for training images: 0\n",
        "Maximum pixel value for training images: 255\n",
        "Minimum pixel value for testing images: 0\n",
        "Maximum pixel value for testing images: 255\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywUFcLSCPIqz"
      },
      "source": [
        "###<b> Count the number of values in both uninfected and parasitized"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcEb9liBPRlu"
      },
      "source": [
        "# Calculate the minimum and maximum pixel values for training images\n",
        "train_min_pixel = X_train.min()\n",
        "train_max_pixel = X_train.max()\n",
        "\n",
        "# Calculate the minimum and maximum pixel values for testing images\n",
        "test_min_pixel = X_test.min()\n",
        "test_max_pixel = X_test.max()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7U71xb2XJe0t"
      },
      "source": [
        "###<b>Normalize the images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqzvvNS9IvsP"
      },
      "source": [
        "# Normalize the training and testing images\n",
        "X_train_normalized = X_train.astype('float32') / 255.0\n",
        "X_test_normalized = X_test.astype('float32') / 255.0\n",
        "\n",
        "# Print the minimum and maximum pixel values after normalization\n",
        "print(\"Minimum pixel value in normalized training images:\", X_train_normalized.min())\n",
        "print(\"Maximum pixel value in normalized training images:\", X_train_normalized.max())\n",
        "print(\"Minimum pixel value in normalized testing images:\", X_test_normalized.min())\n",
        "print(\"Maximum pixel value in normalized testing images:\", X_test_normalized.max())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAT1eVTrKiDy"
      },
      "source": [
        "####<b> Observations and insights: _____</b>\n",
        "\n",
        "Minimum pixel value in normalized training images: 0.0\n",
        "Maximum pixel value in normalized training images: 1.0\n",
        "Minimum pixel value in normalized testing images: 0.0\n",
        "Maximum pixel value in normalized testing images: 1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NG4meNZBKZ5r"
      },
      "source": [
        "###<b> Plot to check if the data is balanced"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8N4qohCFIvvI"
      },
      "source": [
        "# Count the number of each class in the training and testing datasets\n",
        "train_class_counts = [len(y_train[y_train == 0]), len(y_train[y_train == 1])]\n",
        "test_class_counts = [len(y_test[y_test == 0]), len(y_test[y_test == 1])]\n",
        "\n",
        "# Labels for the classes\n",
        "class_labels = ['Uninfected', 'Parasitized']\n",
        "\n",
        "# Create subplots for the training and testing datasets\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.bar(class_labels, train_class_counts, color='b', alpha=0.7)\n",
        "plt.title('Training Data Class Distribution')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.bar(class_labels, test_class_counts, color='r', alpha=0.7)\n",
        "plt.title('Testing Data Class Distribution')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the length of each class in the training data\n",
        "train_uninfected_count = len(y_train[y_train == 0])\n",
        "train_infected_count = len(y_train[y_train == 1])\n",
        "\n",
        "# Calculate the length of each class in the testing data\n",
        "test_uninfected_count = len(y_test[y_test == 0])\n",
        "test_infected_count = len(y_test[y_test == 1])\n",
        "\n",
        "print(\"Training Data:\")\n",
        "print(\"Uninfected count:\", train_uninfected_count)\n",
        "print(\"Parasitized count:\", train_infected_count)\n",
        "\n",
        "print(\"\\nTesting Data:\")\n",
        "print(\"Uninfected count:\", test_uninfected_count)\n",
        "print(\"Parasitized count:\", test_infected_count)"
      ],
      "metadata": {
        "id": "p7PezK6MJSOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGfRJaffLI-C"
      },
      "source": [
        "####<b> Observations and insights: _____</b>\n",
        "- Training Data:\n",
        "  - Uninfected count: 10895\n",
        "  - Parasitized count: 11151\n",
        "- Testing Data:\n",
        " - Uninfected count: 2781\n",
        "  - Parasitized count: 2731"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16-Er2edMzsD"
      },
      "source": [
        "### <b>Data Exploration</b>\n",
        "Let's visualize the images from the train data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of images to display\n",
        "num_images_to_display = 5\n",
        "\n",
        "# Create a subplot for the images\n",
        "plt.figure(figsize=(15, 5))\n",
        "for i in range(num_images_to_display):\n",
        "    # Select a random index from the training dataset\n",
        "    random_index = random.randint(0, len(X_train) - 1)\n",
        "\n",
        "    # Get the image and label at the selected index\n",
        "    image = X_train[random_index]\n",
        "    label = y_train[random_index]\n",
        "\n",
        "    # Create a subplot for each image\n",
        "    plt.subplot(1, num_images_to_display, i + 1)\n",
        "    plt.imshow(image)\n",
        "    plt.title(f\"Class: {'Parasitized' if label == 1 else 'Uninfected'}\")\n",
        "    plt.axis('off')  # Turn off axis labels\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kjhRVQ3-2Pa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnyS_9IcCZLp"
      },
      "source": [
        "####<b> Observations and insights: _____</b>\n",
        "\n",
        "- Sample Variability: There is a diversity of images within the training set. Each cell displayed has its own unique color pattern, shape, and location/distribution of parasite.\n",
        "- Rotation: Each cell, due to its shape, is position differently. Thus the location of the parasite is oriented uniquely.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ay4oo5HrTDha"
      },
      "source": [
        "###<b> Visualize the images with subplot(6, 6) and figsize = (12, 12)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKmncZ-fTAdD"
      },
      "source": [
        "# Number of images to display\n",
        "num_rows = 6\n",
        "num_cols = 6\n",
        "\n",
        "# Create a subplot for the images\n",
        "plt.figure(figsize=(12, 12))\n",
        "for i in range(num_rows * num_cols):\n",
        "    # Select a random index from the training dataset\n",
        "    random_index = random.randint(0, len(X_train) - 1)\n",
        "\n",
        "    # Get the image and label at the selected index\n",
        "    image = X_train[random_index]\n",
        "    label = y_train[random_index]\n",
        "\n",
        "    # Create a subplot for each image\n",
        "    plt.subplot(num_rows, num_cols, i + 1)\n",
        "    plt.imshow(image)\n",
        "    plt.title(f\"Class: {'Parasitized' if label == 1 else 'Uninfected'}\")\n",
        "    plt.axis('off')  # Turn off axis labels\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTG8UaNNNNso"
      },
      "source": [
        "####<b>Observations and insights: </b>\n",
        "\n",
        "**Parasitized Cells**:\n",
        "\n",
        "- Parasitized cells contain one or more malaria parasites inside them.\n",
        "- The parasites, known as Plasmodium, appear as small, dark-stained structures within the red blood cells.\n",
        "- Parasitized cells exhibit changes in shape due to the presence of the parasites.\n",
        "The presence of malaria pigment (hemozoin) can lead to the appearance of dark granules within parasitized cells.\n",
        "\n",
        "**Uninfected Cells:**\n",
        "\n",
        "- Uninfected cells do not contain malaria parasites.\n",
        "- Uninfected cells maintain their characteristic disc shape and a uniform, clear appearance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifjZ2G0YN20r"
      },
      "source": [
        "###<b> Plotting the mean images for parasitized and uninfected"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yN9X0620Iv1a"
      },
      "source": [
        "# Calculate the mean image for parasitized (infected) cells\n",
        "mean_infected_image = np.mean(X_train[y_train == 1], axis=0)\n",
        "\n",
        "# Calculate the mean image for uninfected cells\n",
        "mean_uninfected_image = np.mean(X_train[y_train == 0], axis=0)\n",
        "\n",
        "# Create a subplot for the mean images\n",
        "plt.figure(figsize=(10, 5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQ4xRQfUOMtm"
      },
      "source": [
        "<b> Mean image for parasitized"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the mean Parasitized image\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(mean_infected_image, cmap='gray')\n",
        "plt.title('Mean Parasitized Cell')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SlgCf1-x2gli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkRt1rYIKE24"
      },
      "source": [
        "<b> Mean image for uninfected"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ji4w0okiIv6o"
      },
      "source": [
        "# Plot the mean uninfected image\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(mean_uninfected_image, cmap='gray')\n",
        "plt.title('Mean Uninfected Cell')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lp9NP8yqPA69"
      },
      "source": [
        "####<b> Observations and insights: _____</b>\n",
        "\n",
        "- Although the images look quite similar, there is a nuance in color saturation and color distribution. Care must be used when evaluating the data, as not accounting for the color nuance could grately skew the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzBagGEzHMHB"
      },
      "source": [
        "### <b>Converting RGB to HSV of Images using OpenCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJFCdE77H1Sg"
      },
      "source": [
        "###<b> Converting the train data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32iwgGz7Iv-E"
      },
      "source": [
        "# Create an empty list to store the converted HSV images\n",
        "X_train_hsv = []\n",
        "\n",
        "# Loop through each RGB image in the training data\n",
        "for rgb_image in X_train:\n",
        "    # Convert RGB to HSV\n",
        "    hsv_image = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2HSV)\n",
        "    X_train_hsv.append(hsv_image)\n",
        "\n",
        "# Convert the list of HSV images to a numpy array\n",
        "X_train_hsv = np.array(X_train_hsv)\n",
        "\n",
        "# Print the shape of the resulting HSV images\n",
        "print(\"Shape of HSV training images:\", X_train_hsv.shape)\n",
        "\n",
        "# Number of HSV images to display\n",
        "num_images_to_display = 5\n",
        "# Create a subplot for the images\n",
        "plt.figure(figsize=(15, 5))\n",
        "for i in range(num_images_to_display):\n",
        "    # Select a random index from the test dataset\n",
        "    random_index = random.randint(0, len(X_train_hsv) - 1)\n",
        "\n",
        "    # Get the HSV image at the selected index\n",
        "    hsv_image = X_train_hsv[random_index]\n",
        "\n",
        "    # Create a subplot for each image\n",
        "    plt.subplot(1, num_images_to_display, i + 1)\n",
        "    plt.imshow(hsv_image, cmap='hsv')\n",
        "    plt.title(f\"Test Image {random_index}\")\n",
        "    plt.axis('off')  # Turn off axis labels\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9a7cFllH794"
      },
      "source": [
        "###<b> Converting the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-kUOULrGpBA"
      },
      "source": [
        "# Create an empty list to store the converted HSV images for the test data\n",
        "X_test_hsv = []\n",
        "\n",
        "# Loop through each RGB image in the test data\n",
        "for rgb_image in X_test:\n",
        "    # Convert RGB to HSV\n",
        "    hsv_image = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2HSV)\n",
        "    X_test_hsv.append(hsv_image)\n",
        "\n",
        "# Convert the list of HSV images to a numpy array\n",
        "X_test_hsv = np.array(X_test_hsv)\n",
        "\n",
        "# Print the shape of the resulting HSV images\n",
        "print(\"Shape of HSV testing images:\", X_test_hsv.shape)\n",
        "\n",
        "# Number of HSV images to display\n",
        "num_images_to_display = 5\n",
        "\n",
        "# Create a subplot for the images\n",
        "plt.figure(figsize=(15, 5))\n",
        "for i in range(num_images_to_display):\n",
        "    # Select a random index from the test dataset\n",
        "    random_index = random.randint(0, len(X_test_hsv) - 1)\n",
        "\n",
        "    # Get the HSV image at the selected index\n",
        "    hsv_image = X_test_hsv[random_index]\n",
        "\n",
        "    # Create a subplot for each image\n",
        "    plt.subplot(1, num_images_to_display, i + 1)\n",
        "    plt.imshow(hsv_image, cmap='hsv')\n",
        "    plt.title(f\"Test Image {random_index}\")\n",
        "    plt.axis('off')  # Turn off axis labels\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xq4_3hv6J3ad"
      },
      "source": [
        "####<b>Observations and insights: _____</b>\n",
        "\n",
        "The HSV (Hue, Saturation, Value) color space can be advantageous for emphasizing specific features or traits of cells that may not be as apparent in the RGB (Red, Green, Blue) color space. For instance, it proves valuable in tasks such as distinguishing objects based on their color or detecting subtle variations in color within an image.\n",
        "\n",
        "In the context of malaria-infected cells, the HSV color space can be particularly informative. It often reveals that the parasitic area of the cells appears as a complementary color when compared to the uninfected portion of the cell. This contrast can aid in identifying and studying the infected regions within the cells more effectively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7x9uDxuJur7"
      },
      "source": [
        "###<b> Processing Images using Gaussian Blurring"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgkB_-J2KhBQ"
      },
      "source": [
        "###<b> Gaussian Blurring on train data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7GtZThUI6ug"
      },
      "source": [
        "# Define the kernel size for Gaussian blur\n",
        "kernel_size = (5, 5)\n",
        "\n",
        "# Apply Gaussian blur to training images and store in X_train_blurred\n",
        "X_train_blurred = [cv2.GaussianBlur(img, kernel_size, 0) for img in X_train_hsv]\n",
        "\n",
        "# Number of blurred images to display\n",
        "num_images_to_display = 5\n",
        "\n",
        "# Create a subplot for the blurred training images\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.suptitle('Blurred Training Images', fontsize=16)\n",
        "for i in range(num_images_to_display):\n",
        "    # Select a random index from the training dataset\n",
        "    random_index = random.randint(0, len(X_train_blurred) - 1)\n",
        "\n",
        "    # Get the blurred HSV image at the selected index\n",
        "    blurred_hsv_image = X_train_blurred[random_index]\n",
        "\n",
        "    # Convert the blurred HSV image back to RGB for display\n",
        "    blurred_rgb_image = cv2.cvtColor(blurred_hsv_image, cv2.COLOR_HSV2RGB)\n",
        "\n",
        "    # Create a subplot for each blurred training image\n",
        "    plt.subplot(2, num_images_to_display, i + 1)\n",
        "    plt.imshow(blurred_rgb_image)\n",
        "    plt.title(f\"Train Image {random_index}\")\n",
        "    plt.axis('off')  # Turn off axis labels\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTsJkRtCKlYZ"
      },
      "source": [
        "###<b> Gaussian Blurring on test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbmMGySOKblh"
      },
      "source": [
        "# Define the kernel size for Gaussian blur\n",
        "kernel_size = (5, 5)\n",
        "\n",
        "# Apply Gaussian blur to training images and store in X_train_blurred\n",
        "X_test_blurred = [cv2.GaussianBlur(img, kernel_size, 0) for img in X_train_hsv]\n",
        "\n",
        "# Number of blurred images to display\n",
        "num_images_to_display = 5\n",
        "\n",
        "# Create a subplot for the blurred training images\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.suptitle('Blurred Training Images', fontsize=16)\n",
        "for i in range(num_images_to_display):\n",
        "    # Select a random index from the training dataset\n",
        "    random_index = random.randint(0, len(X_train_blurred) - 1)\n",
        "\n",
        "    # Get the blurred HSV image at the selected index\n",
        "    blurred_hsv_image = X_test_blurred[random_index]\n",
        "\n",
        "    # Convert the blurred HSV image back to RGB for display\n",
        "    blurred_rgb_image = cv2.cvtColor(blurred_hsv_image, cv2.COLOR_HSV2RGB)\n",
        "\n",
        "    # Create a subplot for each blurred training image\n",
        "    plt.subplot(2, num_images_to_display, i + 1)\n",
        "    plt.imshow(blurred_rgb_image)\n",
        "    plt.title(f\"Train Image {random_index}\")\n",
        "    plt.axis('off')  # Turn off axis labels\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkpR8tQFKplr"
      },
      "source": [
        "####**Observations and insights: _____**\n",
        "\n",
        "**Think About It:**\n",
        "\n",
        "Blurring could be a double-edged sword when it comes to parasite detection.\n",
        "- Noise Reduction: Blurring can help reduce noise, which can improve the overall quality of the images. Cleaner images can make it easier for the detection of the parasites.\n",
        "- Loss of Detail: On the other hand, excessive blurring can lead to a loss of fine details in the image. If the parasites are small and subtle, aggressive blurring might make them less visible and hinder detection.\n",
        "\n",
        "Other visual maniulation technique:\n",
        "- Super-Resolution: Super-resolution techniques can enhance image resolution, potentially making small parasites or structures more visible.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model Building**"
      ],
      "metadata": {
        "id": "G4Vso75QRcej"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4_ZzqDp8T5w"
      },
      "source": [
        "### **Base Model**\n",
        "\n",
        "**Note:** The Base Model has been fully built and evaluated with all outputs shown to give an idea about the process of the creation and evaluation of the performance of a CNN architecture. A similar process can be followed in iterating to build better-performing CNN architectures."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTMSr0Xw6x3b"
      },
      "source": [
        "###<b> Importing the required libraries for building and training our Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8eWxdyDp_ZC"
      },
      "source": [
        "# Library for randomly selecting data points\n",
        "import random\n",
        "\n",
        "# Libraries for performing numerical computations\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Library for creating and showing plots\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Library to interact with the operating system\n",
        "import os\n",
        "\n",
        "# Open Source Computer Vision Library\n",
        "import cv2\n",
        "\n",
        "# TensorFlow modules\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import (\n",
        "    Dense, Conv2D, MaxPool2D, BatchNormalization, Dropout, Flatten, LeakyReLU, MaxPooling2D\n",
        ")\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "\n",
        "# Module for loading and displaying images\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Module for one-hot encoding labels\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Module for plotting model architectures\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "# scikit-learn modules\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# Torchvision modules\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "# Zipfile\n",
        "import zipfile\n",
        "\n",
        "# Operating System Interface\n",
        "import os\n",
        "\n",
        "# Libraries for Image Padding\n",
        "from PIL import Image, ImageOps\n",
        "\n",
        "# Library to add progress bars to loops - tracking progress\n",
        "from tqdm import tqdm\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtayck2-Pm3G"
      },
      "source": [
        "####<B>One Hot Encoding the train and test labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDWl6dVtOMom"
      },
      "outputs": [],
      "source": [
        "# One-hot encode the train labels\n",
        "num_classes = 2  #  Two classes (infected and uninfected)\n",
        "y_train_encoded = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "\n",
        "# One-hot encode the test labels\n",
        "y_test_encoded = tf.keras.utils.to_categorical(y_test, num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmwb4h0h64Km"
      },
      "source": [
        "###<b> Building the model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Define the input shape based on HSV image dimensions\n",
        "input_shape = (128, 128, 3)\n",
        "\n",
        "# Add a Convolutional layer with 32 filters, a 3x3 kernel, and 'relu' activation\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
        "\n",
        "# Add a MaxPooling layer with a 2x2 pool size\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Add another Convolutional layer with 64 filters, a 3x3 kernel, and 'relu' activation\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "# Add another MaxPooling layer with a 2x2 pool size\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Flatten the feature maps\n",
        "model.add(Flatten())\n",
        "\n",
        "# Add a fully connected layer with 128 units and 'relu' activation\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "# Add dropout to reduce overfitting\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Add the output layer with 2 units (for binary classification) and 'softmax' activation\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "3LV1Ad_b4_LK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Sh0OGP268Qm"
      },
      "source": [
        "###<b> Compiling the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGGRMByKOMyG"
      },
      "source": [
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Dt8lFvz6_K6"
      },
      "source": [
        "<b> Using Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPwUYX3KOM34"
      },
      "source": [
        "# Define a ModelCheckpoint callback\n",
        "checkpoint_callback = ModelCheckpoint(\"best_model.h5\", save_best_only=True, monitor='val_loss', mode='min', verbose=1)\n",
        "\n",
        "# Define an EarlyStopping callback\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n",
        "\n",
        "# Define a TensorBoard callback\n",
        "tensorboard_callback = TensorBoard(log_dir='./logs', histogram_freq=1)\n",
        "\n",
        "# Define a learning rate schedule function (e.g., reduce by half every 10 epochs)\n",
        "def lr_schedule(epoch):\n",
        "    initial_learning_rate = 0.001\n",
        "    if epoch < 10:\n",
        "        return initial_learning_rate\n",
        "    else:\n",
        "        return initial_learning_rate * 0.5\n",
        "\n",
        "# Create a LearningRateScheduler callback\n",
        "lr_scheduler_callback = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "# Define a ReduceLROnPlateau callback\n",
        "reduce_lr_callback = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91af114l7DCt"
      },
      "source": [
        "<b> Fit and train our Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_train,\n",
        "    y_train_encoded,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test, y_test_encoded),\n",
        "    callbacks=[checkpoint_callback, early_stopping_callback, tensorboard_callback, lr_scheduler_callback, reduce_lr_callback]\n",
        ")"
      ],
      "metadata": {
        "id": "XysPQsWn5EGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vn7bDXku7Ib8"
      },
      "source": [
        "###<b> Evaluating the model on test data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(X_test, y_test_encoded, verbose=1)\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "print(f\"Test Loss: {test_loss:.4f}\")"
      ],
      "metadata": {
        "id": "mHbgBrZe5Hqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSoNNG_T7PkT"
      },
      "source": [
        "<b> Plotting the confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Convert one-hot encoded predictions to class labels\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true_classes = np.argmax(y_test_encoded, axis=1)\n",
        "\n",
        "# Generate a classification report\n",
        "classification_report_result = classification_report(y_true_classes, y_pred_classes)\n",
        "\n",
        "# Generate a confusion matrix\n",
        "confusion_matrix_result = confusion_matrix(y_true_classes, y_pred_classes)"
      ],
      "metadata": {
        "id": "mwY1yx095NN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWq4jyPL7f5a"
      },
      "source": [
        "<b>Plotting the train and validation curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3h5gAwyW05u"
      },
      "source": [
        "# Extract training and validation loss and accuracy from the history\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "train_accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "# Plot training and validation loss\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Plot training and validation accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_accuracy, label='Training Accuracy')\n",
        "plt.plot(val_accuracy, label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <b>Observation:</b>\n",
        "\n",
        "1. Training Accuracy: The training accuracy increasing and approaching 100% suggests that the model is able to fit the training data. However, there is a slightly erratic pattern:\n",
        "\n",
        "  - Initial Sharp Climb: At the beginning of training, the model is learning and adapting quickly to the training data. It starts with low accuracy and rapidly improves as it fits the training data more closely.\n",
        "  - Small Window of Climbing: This phase might be a period where the model continues to improve and learn from the training data, albeit at a slower pace. The accuracy curve shows some fluctuations or plateaus during this time.\n",
        "  - Plummet Back to 0: The sudden drop to near-zero accuracy is a strong indicator of overfitting. Overfitting occurs when the model has learned to memorize the training data instead of generalizing from it. It becomes too specialized and fails to perform well on unseen data (validation or test data).\n",
        "  - Sharp Incline Back Up: The model starts to \"recover\" from overfitting as training continues. This can happen because the model's weights are being updated during training, and it starts to generalize better.\n",
        "  - Steady Climb: In this phase, the model continues to improve its performance on the training data while also generalizing well to unseen data. The accuracy steadily increases.\n",
        "\n",
        "2. Validation Accuracy Stagnation: The validation accuracy remaining stagnant and not improving suggests that the model's performance on unseen or validation data is not getting better, even though it's improving on the training data.\n",
        "  - This often means that the model is not generalizing well to new, unseen data.\n",
        "  - The phenomenon of overfitting occurs when a model becomes too complex and starts fitting the noise or random variations in the training data, rather than learning the underlying patterns. As a result, the model performs well on the training data but poorly on new, unseen data because it has essentially memorized the training dataset."
      ],
      "metadata": {
        "id": "yagu_l2bu861"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCDgxiFnXSek"
      },
      "source": [
        "So now let's try to build another model with few more add on layers and try to check if we can try to improve the model. Therefore try to build a model by adding few layers if required and altering the activation functions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tJeklwR77rs"
      },
      "source": [
        "###<b> Model 1\n",
        "####<b> Trying to improve the performance of our model by adding new layers\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clear the backend session to release resources\n",
        "backend.clear_session()\n",
        "\n",
        "# Fixing the seed for random number generators to ensure reproducibility\n",
        "np.random.seed(42)       # Fixing seed for NumPy random number generator\n",
        "random.seed(42)          # Fixing seed for Python's random module\n",
        "tf.random.set_seed(42)   # Fixing seed for TensorFlow's random operations\n",
        "\n",
        "# Suppressing warnings\n",
        "warnings.filterwarnings(\"default\")"
      ],
      "metadata": {
        "id": "J-NnG6Rp9_w7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DT99NdnzZW3n"
      },
      "source": [
        "###<b> Building the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TaSet9DONGV"
      },
      "source": [
        "# Define hyperparameters and regularization strength\n",
        "learning_rate = 1e-4\n",
        "num_epochs = 20\n",
        "batch_size = 32\n",
        "dropout_rate = 0.5\n",
        "l2_regularization = 1e-4\n",
        "\n",
        "# Create a function to build the model\n",
        "def create_model(input_shape):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Convolutional Layers\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(l2_regularization)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l2(l2_regularization)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    # Flatten and fully connected layers\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256, activation='relu', kernel_regularizer=l2(l2_regularization)))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(128, activation='relu', kernel_regularizer=l2(l2_regularization)))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "\n",
        "    # Output layer\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "    # Compile the model\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6cTCOAVZZpI"
      },
      "source": [
        "###<b> Compiling the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWcQhKidONIr"
      },
      "source": [
        "# Held within the \"Build the Model\" function (above)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PSskadUZhUt"
      },
      "source": [
        "<b> Using Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4_T2_sKONMA"
      },
      "source": [
        "# Held within the \"Fit and Train the model\" (below)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYLgQK9DZkoc"
      },
      "source": [
        "<b>Fit and Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7S7LmVTZjrd"
      },
      "source": [
        "# Initialize stratified k-fold cross-validation\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Store results\n",
        "cv_scores = []\n",
        "\n",
        "# Iterate through cross-validation splits\n",
        "for train_idx, val_idx in kfold.split(X_train, y_train):\n",
        "    # Split the data\n",
        "    X_train_fold, X_val_fold = X_train[train_idx], X_train[val_idx]\n",
        "    y_train_fold, y_val_fold = y_train_encoded[train_idx], y_train_encoded[val_idx]\n",
        "\n",
        "    # Create and compile the model\n",
        "    model = create_model(input_shape)\n",
        "\n",
        "    # Early stopping callback\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(\n",
        "        X_train_fold,\n",
        "        y_train_fold,\n",
        "        epochs=num_epochs,\n",
        "        batch_size=batch_size,\n",
        "        validation_data=(X_val_fold, y_val_fold),\n",
        "        callbacks=[early_stopping],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Evaluate the model on the validation data\n",
        "    _, accuracy = model.evaluate(X_val_fold, y_val_fold, verbose=0)\n",
        "    cv_scores.append(accuracy)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHABkGRzZwyt"
      },
      "source": [
        "###<b> Evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yie1Z-R6Zjt_"
      },
      "source": [
        "# Calculate the mean and standard deviation of cross-validation scores\n",
        "mean_accuracy = np.mean(cv_scores)\n",
        "std_accuracy = np.std(cv_scores)\n",
        "\n",
        "print(f\"Mean CV Accuracy: {mean_accuracy * 100:.2f}%\")\n",
        "print(f\"Standard Deviation of CV Accuracy: {std_accuracy * 100:.2f}%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCJEZ6cqZywk"
      },
      "source": [
        "<b> Plotting the confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmuJFfUjZjws"
      },
      "source": [
        "y_pred_classes = np.argmax(model.predict(X_val_fold), axis=1)\n",
        "y_true_classes = np.argmax(y_val_fold, axis=1)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "confusion_mtx = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "\n",
        "# Plot the confusion matrix as a heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion_mtx, annot=True, fmt='d', cmap='Blues', xticklabels=['Uninfected', 'Infected'], yticklabels=['Uninfected', 'Infected'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)  # Convert softmax output to class labels\n",
        "\n",
        "# Convert one-hot encoded labels to class labels\n",
        "y_true_classes = np.argmax(y_test_encoded, axis=1)\n",
        "\n",
        "# Generate the classification report\n",
        "report = classification_report(y_true_classes, y_pred_classes, target_names=['Uninfected', 'Infected'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roDugWeKaVDW"
      },
      "source": [
        "<b> Plotting the train and the validation curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JakeVNnbZjzh"
      },
      "source": [
        "# Access the training history\n",
        "history = model.fit(\n",
        "    X_train_fold,\n",
        "    y_train_fold,\n",
        "    epochs=num_epochs,\n",
        "    batch_size=batch_size,\n",
        "    validation_data=(X_val_fold, y_val_fold),\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Extract training and validation loss and accuracy from the history\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "train_accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "# Plot training and validation loss\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Plot training and validation accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_accuracy, label='Training Accuracy')\n",
        "plt.plot(val_accuracy, label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zsx7jVjaiO9V"
      },
      "source": [
        "###<b>Think about it:</b><br>\n",
        "Now let's build a model with LeakyRelu as the activation function  \n",
        "\n",
        "*  Can the model performance be improved if we change our activation function to LeakyRelu?\n",
        "*  Can BatchNormalization improve our model?\n",
        "\n",
        "Let us try to build a model using BatchNormalization and using LeakyRelu as our activation function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JU4qr7amiXds"
      },
      "source": [
        "###<b> Model 2 with Batch Normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOXd_ciyZj2n"
      },
      "source": [
        "# Clear the backend session to release resources\n",
        "backend.clear_session()\n",
        "\n",
        "# Fixing the seed for random number generators to ensure reproducibility\n",
        "np.random.seed(42)       # Fixing seed for NumPy random number generator\n",
        "random.seed(42)          # Fixing seed for Python's random module\n",
        "tf.random.set_seed(42)   # Fixing seed for TensorFlow's random operations\n",
        "\n",
        "# Suppressing warnings\n",
        "warnings.filterwarnings(\"default\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kDMUu-U8vV3"
      },
      "source": [
        "###<b> Building the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJBcwhtbiu0l"
      },
      "source": [
        "# Create a new Sequential model\n",
        "new_model = Sequential()\n",
        "\n",
        "# Define the input shape based on HSV image dimensions\n",
        "input_shape = (128, 128, 3)\n",
        "\n",
        "# Add a Convolutional layer with 32 filters, a 3x3 kernel, BatchNormalization, and LeakyReLU activation\n",
        "new_model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
        "new_model.add(BatchNormalization())\n",
        "new_model.add(LeakyReLU(alpha=0.1))\n",
        "\n",
        "# Add a MaxPooling layer with a 2x2 pool size\n",
        "new_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Add another Convolutional layer with 64 filters, a 3x3 kernel, BatchNormalization, and LeakyReLU activation\n",
        "new_model.add(Conv2D(64, (3, 3)))\n",
        "new_model.add(BatchNormalization())\n",
        "new_model.add(LeakyReLU(alpha=0.1))\n",
        "\n",
        "# Add another MaxPooling layer with a 2x2 pool size\n",
        "new_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Flatten the feature maps\n",
        "new_model.add(Flatten())\n",
        "\n",
        "# Add a fully connected layer with 128 units, BatchNormalization, and LeakyReLU activation\n",
        "new_model.add(Dense(128))\n",
        "new_model.add(BatchNormalization())\n",
        "new_model.add(LeakyReLU(alpha=0.1))\n",
        "\n",
        "# Add dropout to reduce overfitting\n",
        "new_model.add(Dropout(0.5))\n",
        "\n",
        "# Add the output layer with 2 units (for binary classification) and 'softmax' activation\n",
        "new_model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "# Display the new model summary\n",
        "new_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9WQ7-cOLIQy"
      },
      "source": [
        "###<b>Compiling the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SiRoyZ7LHSL"
      },
      "source": [
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=1e-4)\n",
        "new_model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOVzX0WTDUEy"
      },
      "source": [
        "<b> Using callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jC0FcITongxx"
      },
      "source": [
        "# Define callbacks\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    'best_model.h5',  # Save the best model to this file\n",
        "    save_best_only=True,  # Save only the best model\n",
        "    monitor='val_loss',  # Monitor validation loss\n",
        "    mode='min',  # Minimize validation loss\n",
        "    verbose=1  # Display messages\n",
        ")\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',  # Monitor validation loss\n",
        "    patience=10,  # Stop training if no improvement for 10 epochs\n",
        "    restore_best_weights=True,  # Restore weights of the best model\n",
        "    verbose=1  # Display messages\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',  # Monitor validation loss\n",
        "    factor=0.5,  # Reduce learning rate by half when triggered\n",
        "    patience=3,  # Number of epochs with no improvement before reducing LR\n",
        "    verbose=1  # Display messages\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rxj3AcS0Dqm8"
      },
      "source": [
        "<b>Fit and train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMy-4IGajL31"
      },
      "source": [
        "# Split training data into training and validation sets\n",
        "X_train, X_val, y_train_encoded, y_val_encoded = train_test_split(\n",
        "    X_train, y_train_encoded, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Train the model with callbacks\n",
        "history = new_model.fit(\n",
        "    X_train,\n",
        "    y_train_encoded,\n",
        "    epochs=num_epochs,\n",
        "    batch_size=batch_size,\n",
        "    validation_data=(X_val, y_val_encoded),\n",
        "    callbacks=[model_checkpoint, early_stopping, reduce_lr],\n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9DkuwVYDtc3"
      },
      "source": [
        "<b>Plotting the train and validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILu-oHB_jxGY"
      },
      "source": [
        "# Extract training and validation accuracy from the history\n",
        "train_accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "# Plot training and validation accuracy\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_accuracy, label='Training Accuracy')\n",
        "plt.plot(val_accuracy, label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSREnGkgDz6N"
      },
      "source": [
        "###<b>Evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZGH8gE089Gx"
      },
      "source": [
        "# Evaluate the model on the test dataset\n",
        "test_loss, test_accuracy = new_model.evaluate(X_test, y_test_encoded, verbose=1)\n",
        "\n",
        "# Print the test loss and accuracy\n",
        "print(f'Test Loss: {test_loss:.4f}')\n",
        "print(f'Test Accuracy: {test_accuracy:.4f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiIQnwKaJ27O"
      },
      "source": [
        "####<b>Observations and insights: ____</b>\n",
        "\n",
        "- Test Performance*: Model 2 achieved a test loss of 0.1599 and a test accuracy of 95.05%, indicating strong generalization to unseen data. The f1-score of 0.95 for both classes suggests a balanced performance in terms of precision and recall.\n",
        "- Training and Validation Accuracy: During training, the model's training accuracy steadily increased from 0.7384 to 0.9961, while the validation accuracy also grew from 0.5295 to 0.9449.\n",
        "- Overfitting, there is some evidence of it in Model 2. The training accuracy consistently outpaces the validation accuracy, and the large gap between training and validation accuracy in the later stages of training suggests that the model has learned the training data too well, leading to overfitting. EarlyStopping and ReduceLROnPlateau callbacks help mitigate this by stopping training when validation loss stalls, but there is still room for improvement."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDL1BQZ7_JxS"
      },
      "source": [
        "<b> Generate the classification report and confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pB-CYdwC9V8P"
      },
      "source": [
        "# Make predictions on the test data\n",
        "y_pred = new_model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)  # Convert softmax output to class labels\n",
        "\n",
        "# Convert one-hot encoded labels to class labels\n",
        "y_true_classes = np.argmax(y_test_encoded, axis=1)\n",
        "\n",
        "# Generate the classification report\n",
        "report = classification_report(y_true_classes, y_pred_classes, target_names=['Uninfected', 'Infected'])\n",
        "\n",
        "# Generate the confusion matrix\n",
        "confusion_mtx = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "\n",
        "# Print the classification report\n",
        "print(report)\n",
        "\n",
        "# Print the confusion matrix\n",
        "print(confusion_mtx)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUwBBVzuijlU"
      },
      "source": [
        "###**Think About It :**<br>\n",
        "\n",
        "* Can we improve the model with Image Data Augmentation?\n",
        "* References to image data augmentation can be seen below:\n",
        "  *   [Image Augmentation for Computer Vision](https://www.mygreatlearning.com/blog/understanding-data-augmentation/)\n",
        "  *   [How to Configure Image Data Augmentation in Keras?](https://machinelearningmastery.com/how-to-configure-image-data-augmentation-when-training-deep-learning-neural-networks/)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYVJZ0Psi0D0"
      },
      "source": [
        "###<b>Model 3 with Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ddfrhcLihpz"
      },
      "source": [
        "# Clear the backend session to release resources\n",
        "backend.clear_session()\n",
        "\n",
        "# Fixing the seed for random number generators to ensure reproducibility\n",
        "np.random.seed(42)       # Fixing seed for NumPy random number generator\n",
        "random.seed(42)          # Fixing seed for Python's random module\n",
        "tf.random.set_seed(42)   # Fixing seed for TensorFlow's random operations\n",
        "\n",
        "# Suppressing warnings\n",
        "warnings.filterwarnings(\"default\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqOnCq3FZ6JG"
      },
      "source": [
        "###<b> Use image data generator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the ImageDataGenerator with desired augmentations\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=40,  # Randomly rotate images by up to 40 degrees\n",
        "    width_shift_range=0.2,  # Randomly shift the width by up to 20% of the image width\n",
        "    height_shift_range=0.2,  # Randomly shift the height by up to 20% of the image height\n",
        "    shear_range=0.2,  # Randomly apply shear transformations\n",
        "    zoom_range=0.2,  # Randomly zoom in and out\n",
        "    horizontal_flip=True,  # Randomly flip images horizontally\n",
        "    fill_mode='nearest'  # Fill missing pixels using the nearest available pixel\n",
        ")"
      ],
      "metadata": {
        "id": "EqlZamqDa5ws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2cJN07Bbofx"
      },
      "source": [
        "###**Think About It :**<br>\n",
        "\n",
        "*  Check if the performance of the model can be improved by changing different parameters in the ImageDataGenerator.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "341Ilg5McowX"
      },
      "source": [
        "####<B>Visualizing Augmented images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ws3BE91RbFBy"
      },
      "source": [
        "# Load an example image\n",
        "img_path = '/content/drive/MyDrive/cell_images/test/parasitized/C39P4thinF_original_IMG_20150622_105253_cell_105.png'\n",
        "img = image.load_img(img_path)\n",
        "x = image.img_to_array(img)\n",
        "x = x.reshape((1,) + x.shape)  # Reshape to (1, height, width, channels)\n",
        "\n",
        "# Generate augmented images\n",
        "plt.figure(figsize=(10, 10))\n",
        "i = 0\n",
        "for batch in datagen.flow(x, batch_size=1):\n",
        "    plt.subplot(3, 3, i + 1)\n",
        "    imgplot = plt.imshow(image.array_to_img(batch[0]))\n",
        "    i += 1\n",
        "    if i % 9 == 0:  # Display 9 augmented images\n",
        "        break\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfCMCaAZdK3o"
      },
      "source": [
        "####<b>Observations and insights: ____</b>\n",
        "\n",
        "- The example cell images can either be low or high image quality\n",
        "- The color variation is clear. The images are consistently colored\n",
        "- The image sizes are all the same dimension\n",
        "- The images do not have any noise, the backgrounds are solid black\n",
        "- There does not seem to be any stains or smudges that can impat the analysis\n",
        "- Due to the intense zoomed-in effect, some of the slide examples parasitized, but a distinct parasite spot could not be seen by the eye"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrpS4Azamjs4"
      },
      "source": [
        "###<b>Building the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVELJI8uihsz"
      },
      "source": [
        "# Define constants\n",
        "input_shape = (128, 128, 3)  # Adjust based on image dimensions\n",
        "num_classes = 2  # Number of classes (e.g., 'Infected' and 'Uninfected')\n",
        "batch_size = 32\n",
        "num_epochs = 20\n",
        "\n",
        "\n",
        "# Create an instance of the ImageDataGenerator for augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Build the CNN model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(lr=1e-4),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-HrtTMJnEPl"
      },
      "source": [
        "<b>Using Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMWPxLvdihvf"
      },
      "source": [
        "# Define callback parameters\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    'best_model.h5',  # Save the best model to this file\n",
        "    save_best_only=True,  # Save only the best model\n",
        "    monitor='val_loss',  # Monitor validation loss\n",
        "    mode='min',  # Minimize validation loss\n",
        "    verbose=1  # Display messages\n",
        ")\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',  # Monitor validation loss\n",
        "    patience=10,  # Stop training if no improvement for 10 epochs\n",
        "    restore_best_weights=True,  # Restore weights of the best model\n",
        "    verbose=1  # Display messages\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',  # Monitor validation loss\n",
        "    factor=0.5,  # Reduce learning rate by half when triggered\n",
        "    patience=3,  # Number of epochs with no improvement before reducing LR\n",
        "    verbose=1  # Display messages\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEeOIRrCnMBh"
      },
      "source": [
        "<b> Fit and Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_2dSGYMihyk"
      },
      "source": [
        "# Split training data into training and validation sets\n",
        "X_train, X_val, y_train_encoded, y_val_encoded = train_test_split(\n",
        "    X_train, y_train_encoded, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Create a data generator for training with data augmentation\n",
        "train_generator = datagen.flow(X_train, y_train_encoded, batch_size=batch_size)\n",
        "\n",
        "\n",
        "# Train the model with augmented data\n",
        "history = model.fit(train_generator,\n",
        "                    steps_per_epoch=len(X_train) // batch_size,\n",
        "                    epochs=num_epochs,\n",
        "                    validation_data=(X_val, y_val_encoded),\n",
        "                    callbacks=[model_checkpoint, early_stopping, reduce_lr]\n",
        "                    )\n",
        "\n",
        "\n",
        "# Evaluate the model on the test dataset (X_test, y_test_encoded)\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test_encoded, verbose=1)\n",
        "print(f'Test Loss: {test_loss:.4f}')\n",
        "print(f'Test Accuracy: {test_accuracy:.4f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EFWVEUKoM1U"
      },
      "source": [
        "###<B>Evaluating the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8twGIoxWnrCb"
      },
      "source": [
        "<b>Plot the train and validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjB4IecBih2K"
      },
      "source": [
        "# Extract training and validation accuracy from the history object\n",
        "train_accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "# Create a range of epochs for the x-axis\n",
        "epochs = range(1, len(train_accuracy) + 1)\n",
        "\n",
        "# Plot training and validation accuracy\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs, train_accuracy, label='Training Accuracy')\n",
        "plt.plot(epochs, val_accuracy, label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_VDQxXwoe6u"
      },
      "source": [
        "<B>Plotting the classification report and confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxdOpuzJoj8l"
      },
      "source": [
        "# Make predictions on the test data\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)  # Convert softmax output to class labels\n",
        "\n",
        "# Convert one-hot encoded labels to class labels\n",
        "y_true_classes = np.argmax(y_test_encoded, axis=1)\n",
        "\n",
        "# Generate the classification report\n",
        "report = classification_report(y_true_classes, y_pred_classes, target_names=['Uninfected', 'Infected'])\n",
        "\n",
        "# Generate the confusion matrix\n",
        "confusion_mtx = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "\n",
        "# Print the classification report\n",
        "print(report)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion_mtx, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Uninfected', 'Infected'],\n",
        "            yticklabels=['Uninfected', 'Infected'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obzJSEF5ypj-"
      },
      "source": [
        "<b> Now, let us try to use a pretrained model like VGG16 and check how it performs on our data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ra-GUCjbLHGg"
      },
      "source": [
        "### **Pre-trained model (VGG16)**\n",
        "- Import VGG16 network upto any layer you choose\n",
        "- Add Fully Connected Layers on top of it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dH2_XWNLyac"
      },
      "source": [
        "# Define a custom input shape\n",
        "custom_input_shape = (128, 128, 3)\n",
        "\n",
        "# Load the VGG16 model with pre-trained weights (excluding top layers)\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_tensor=Input(shape=custom_input_shape))\n",
        "\n",
        "# Freeze the layers of the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Choose a layer from the base model to serve as the new top layer\n",
        "chosen_layer = base_model.get_layer('block5_pool')\n",
        "\n",
        "# Create a new model that includes the base model up to the chosen layer\n",
        "new_model = Model(inputs=base_model.input, outputs=chosen_layer.output)\n",
        "\n",
        "# Add fully connected layers on top of the chosen layer\n",
        "x = Flatten()(new_model.output)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "output = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "# Create the final model\n",
        "final_model = Model(inputs=new_model.input, outputs=output)\n",
        "\n",
        "# Print the model summary\n",
        "final_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mhoug92KFWPa"
      },
      "source": [
        "###<b>Compiling the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdJ8C0L5Lkyt"
      },
      "source": [
        "# Compile the model and specify the optimizer, loss function, and metrics\n",
        "final_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBPzjtxcFLQt"
      },
      "source": [
        "<b> using callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qS3skmQBR4if"
      },
      "source": [
        "# Define callback parameters\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    'best_model.h5',  # Save the best model to this file\n",
        "    save_best_only=True,  # Save only the best model\n",
        "    monitor='val_loss',  # Monitor validation loss\n",
        "    mode='min',  # Minimize validation loss\n",
        "    verbose=1  # Display messages\n",
        ")\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',  # Monitor validation loss\n",
        "    patience=10,  # Stop training if no improvement for 10 epochs\n",
        "    restore_best_weights=True,  # Restore weights of the best model\n",
        "    verbose=1  # Display messages\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',  # Monitor validation loss\n",
        "    factor=0.5,  # Reduce learning rate by half when triggered\n",
        "    patience=3,  # Number of epochs with no improvement before reducing LR\n",
        "    verbose=1  # Display messages\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_ZeobGmFIOF"
      },
      "source": [
        "<b>Fit and Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6sSx39uL1mS"
      },
      "source": [
        "# Train the model\n",
        "history = final_model.fit( X_train,\n",
        "    y_train_encoded,\n",
        "    epochs=num_epochs,\n",
        "    batch_size=batch_size,\n",
        "    validation_data=(X_val, y_val_encoded),\n",
        "    verbose=1,\n",
        "    callbacks=[model_checkpoint, early_stopping, reduce_lr])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0WI9dvDFBaR"
      },
      "source": [
        "<b>Plot the train and validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKmS2XyiMBqb"
      },
      "source": [
        "# Extract training and validation accuracy from the history object\n",
        "train_accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "# Create a range of epochs for the x-axis\n",
        "epochs = range(1, len(train_accuracy) + 1)\n",
        "\n",
        "# Plot training and validation accuracy\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs, train_accuracy, label='Training Accuracy')\n",
        "plt.plot(epochs, val_accuracy, label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = final_model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)  # Convert softmax output to class labels\n",
        "\n",
        "# Convert one-hot encoded labels to class labels\n",
        "y_true_classes = np.argmax(y_test_encoded, axis=1)\n",
        "\n",
        "# Generate the classification report\n",
        "report = classification_report(y_true_classes, y_pred_classes, target_names=['Uninfected', 'Infected'])\n",
        "\n",
        "# Generate the confusion matrix\n",
        "confusion_mtx = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "\n",
        "# Print the classification report\n",
        "print(report)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion_mtx, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Uninfected', 'Infected'],\n",
        "            yticklabels=['Uninfected', 'Infected'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mb3jUduI0BNs"
      },
      "source": [
        "###**Observations and insights: _____**\n",
        "\n",
        "*   What can be observed from the validation and train curves?\n",
        "- Test Performance: Model 4 achieved an impressive f1-score of 0.97 for both classes, indicating a strong balance between precision and recall. The validation accuracy started at 96.51% and ended at 96.85%, while the training accuracy started at 95.02% and ended at 99.98%. Training was stopped early, suggesting that the model had already converged and further training was not necessary.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ykl7xLODEoix"
      },
      "source": [
        "###<b> Evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxcgkSoivwWf"
      },
      "source": [
        "# Evaluate the model on the test dataset\n",
        "test_loss, test_accuracy = final_model.evaluate(X_test, y_test_encoded, verbose=2)\n",
        "\n",
        "# Print the test loss and accuracy\n",
        "print(f'Test Loss: {test_loss:.4f}')\n",
        "print(f'Test Accuracy: {test_accuracy:.4f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_lr-dUHE77F"
      },
      "source": [
        "<b>Plotting the classification report and confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jns2wf2HMBto"
      },
      "source": [
        "# Make predictions on the test data\n",
        "y_pred = final_model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)  # Convert softmax output to class labels\n",
        "\n",
        "# Convert one-hot encoded labels to class labels\n",
        "y_true_classes = np.argmax(y_test_encoded, axis=1)\n",
        "\n",
        "# Generate the classification report\n",
        "report = classification_report(y_true_classes, y_pred_classes, target_names=['Uninfected', 'Infected'])\n",
        "\n",
        "# Generate the confusion matrix\n",
        "confusion_mtx = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "\n",
        "# Print the classification report\n",
        "print(report)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion_mtx, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Uninfected', 'Infected'],\n",
        "            yticklabels=['Uninfected', 'Infected'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEZPA_mN0tUo"
      },
      "source": [
        "###<b>Think about it:</b>\n",
        "*  What observations and insights can be drawn from the confusion matrix and classification report?\n",
        "  - In summary, the reports suggests that the model performs well for both \"Uninfected\" and \"Infected\" classes, with high precision, recall, and F1-scores. The overall accuracy is also excellent, and the model is robust in handling class imbalance.\n",
        "\n",
        "*  Choose the model with the best accuracy scores from all the above models and save it as a final model.\n",
        "  - The final model is Model 3: The Image Data Augmentation Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Smzi8y5AEYIi"
      },
      "source": [
        "####<b> Observations and Conclusions drawn from the final model: _____</b>\n",
        "\n",
        "Overall, Model 4 performed exceptionally well, achieving high accuracy, an excellent f1-score, and a well-balanced confusion matrix. The early stopping indicates that the model reached its optimal performance quickly during training.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yo6IpgOZ1n-g"
      },
      "source": [
        "**Improvements that can be done:**<br>\n",
        "\n",
        "\n",
        "*  Can the model performance be improved using other pre-trained models or different CNN architecture?\n",
        "*  You can try to build a model using these HSV images and compare them with your other models."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an empty list to store the converted HSV images\n",
        "X_train_hsv = []\n",
        "\n",
        "# Loop through each RGB image in the training data\n",
        "for rgb_image in X_train:\n",
        "    # Convert RGB to HSV\n",
        "    hsv_image = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2HSV)\n",
        "    X_train_hsv.append(hsv_image)\n",
        "\n",
        "# Convert the list of HSV images to a numpy array\n",
        "X_train_hsv = np.array(X_train_hsv)\n",
        "\n",
        "# Print the shape of the resulting HSV images\n",
        "print(\"Shape of HSV training images:\", X_train_hsv.shape)\n",
        "\n",
        "# Number of HSV images to display\n",
        "num_images_to_display = 5\n",
        "# Create a subplot for the images\n",
        "plt.figure(figsize=(15, 5))\n",
        "for i in range(num_images_to_display):\n",
        "    # Select a random index from the test dataset\n",
        "    random_index = random.randint(0, len(X_train_hsv) - 1)\n",
        "\n",
        "    # Get the HSV image at the selected index\n",
        "    hsv_image = X_train_hsv[random_index]\n",
        "\n",
        "    # Create a subplot for each image\n",
        "    plt.subplot(1, num_images_to_display, i + 1)\n",
        "    plt.imshow(hsv_image, cmap='hsv')\n",
        "    plt.title(f\"Test Image {random_index}\")\n",
        "    plt.axis('off')  # Turn off axis labels\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JI5EqRh3QjH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an empty list to store the converted HSV images for the test data\n",
        "X_test_hsv = []\n",
        "\n",
        "# Loop through each RGB image in the test data\n",
        "for rgb_image in X_test:\n",
        "    # Convert RGB to HSV\n",
        "    hsv_image = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2HSV)\n",
        "    X_test_hsv.append(hsv_image)\n",
        "\n",
        "# Convert the list of HSV images to a numpy array\n",
        "X_test_hsv = np.array(X_test_hsv)\n",
        "\n",
        "# Print the shape of the resulting HSV images\n",
        "print(\"Shape of HSV testing images:\", X_test_hsv.shape)\n",
        "\n",
        "# Number of HSV images to display\n",
        "num_images_to_display = 5\n",
        "\n",
        "# Create a subplot for the images\n",
        "plt.figure(figsize=(15, 5))\n",
        "for i in range(num_images_to_display):\n",
        "    # Select a random index from the test dataset\n",
        "    random_index = random.randint(0, len(X_test_hsv) - 1)\n",
        "\n",
        "    # Get the HSV image at the selected index\n",
        "    hsv_image = X_test_hsv[random_index]\n",
        "\n",
        "    # Create a subplot for each image\n",
        "    plt.subplot(1, num_images_to_display, i + 1)\n",
        "    plt.imshow(hsv_image, cmap='hsv')\n",
        "    plt.title(f\"Test Image {random_index}\")\n",
        "    plt.axis('off')  # Turn off axis labels\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0Urx3_9WQtTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MODEL 1\n",
        "\n",
        "# Clear the backend session to release resources\n",
        "backend.clear_session()\n",
        "\n",
        "# Fixing the seed for random number generators to ensure reproducibility\n",
        "np.random.seed(42)       # Fixing seed for NumPy random number generator\n",
        "random.seed(42)          # Fixing seed for Python's random module\n",
        "tf.random.set_seed(42)   # Fixing seed for TensorFlow's random operations\n",
        "\n",
        "# Suppressing warnings\n",
        "warnings.filterwarnings(\"default\")\n",
        "\n",
        "# Calculate class weights manually\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "\n",
        "# Create a Sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Add the first Convolutional layer with 32 filters, a 3x3 kernel, and 'relu' activation\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)))\n",
        "\n",
        "# Add a MaxPooling layer with a 2x2 pool size\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Add another Convolutional layer with 64 filters, a 3x3 kernel, and 'relu' activation\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "# Add another MaxPooling layer with a 2x2 pool size\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Flatten the feature maps\n",
        "model.add(Flatten())\n",
        "\n",
        "# Add a fully connected layer with 128 units and 'relu' activation\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "# Add dropout to reduce overfitting\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Add the output layer with 2 units (for binary classification) and 'softmax' activation\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()\n",
        "\n",
        "# Define callbacks\n",
        "model_checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True, verbose=1)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6, verbose=1)\n",
        "\n",
        "# Convert class_weights array to a dictionary\n",
        "class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train_hsv,\n",
        "    y_train_encoded,\n",
        "    validation_split=0.2,\n",
        "    epochs=32,\n",
        "    batch_size=32,\n",
        "    callbacks=[model_checkpoint, early_stopping, reduce_lr],\n",
        "    verbose=1,\n",
        "    class_weight=class_weights_dict\n",
        ")\n",
        "\n",
        "# Plot training and validation accuracy\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Evaluate the model on test data\n",
        "test_loss, test_accuracy = model.evaluate(X_test_hsv, y_test_encoded)\n",
        "\n",
        "# Print test loss and accuracy\n",
        "print(f'Test Loss: {test_loss:.4f}')\n",
        "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
        "\n",
        "# Generate classification report\n",
        "y_pred = model.predict(X_test_hsv)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "target_names = ['Uninfected', 'Parasitized']\n",
        "print(classification_report(np.argmax(y_test_encoded, axis=1), y_pred_classes, target_names=target_names))\n",
        "\n",
        "# Generate confusion matrix\n",
        "confusion_mtx = confusion_matrix(np.argmax(y_test_encoded, axis=1), y_pred_classes)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion_mtx, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "4auryKUV-DYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MODEL 2\n",
        "\n",
        "# Clear the backend session to release resources\n",
        "backend.clear_session()\n",
        "\n",
        "# Fixing the seed for random number generators to ensure reproducibility\n",
        "np.random.seed(42)       # Fixing seed for NumPy random number generator\n",
        "random.seed(42)          # Fixing seed for Python's random module\n",
        "tf.random.set_seed(42)   # Fixing seed for TensorFlow's random operations\n",
        "\n",
        "# Suppressing warnings\n",
        "warnings.filterwarnings(\"default\")\n",
        "\n",
        "# Calculate class weights manually\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "\n",
        "# Create a Sequential model\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)))  # L2 regularization\n",
        "model.add(Dropout(0.7))  # Increased dropout rate\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Define callbacks\n",
        "model_checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True, verbose=1)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6, verbose=1)\n",
        "\n",
        "# Convert class_weights array to a dictionary\n",
        "class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train_hsv,\n",
        "    y_train_encoded,\n",
        "    validation_split=0.2,\n",
        "    epochs=32,\n",
        "    batch_size=32,\n",
        "    callbacks=[model_checkpoint, early_stopping, reduce_lr],\n",
        "    verbose=1,\n",
        "    class_weight=class_weights_dict\n",
        ")\n",
        "\n",
        "# Plot training and validation accuracy\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Evaluate the model on test data\n",
        "test_loss, test_accuracy = model.evaluate(X_test_hsv, y_test_encoded)\n",
        "\n",
        "# Print test loss and accuracy\n",
        "print(f'Test Loss: {test_loss:.4f}')\n",
        "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
        "\n",
        "# Generate classification report\n",
        "y_pred = model.predict(X_test_hsv)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "target_names = ['Uninfected', 'Parasitized']\n",
        "print(classification_report(np.argmax(y_test_encoded, axis=1), y_pred_classes, target_names=target_names))\n",
        "\n",
        "# Generate confusion matrix\n",
        "confusion_mtx = confusion_matrix(np.argmax(y_test_encoded, axis=1), y_pred_classes)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion_mtx, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "FNgGR7CIRiy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJB6yf2EczFk"
      },
      "source": [
        "#### **Insights**\n",
        "\n",
        "####**Refined insights**:\n",
        "- What are the most meaningful insights from the data relevant to the problem?\n",
        "\n",
        "**Class Distribution**:\n",
        "  - The class distribution for the dataset, which consists of 24,958 training images and 2,600 test images, is as follows:\n",
        "    - Training Set:\n",
        "      - Parasitized Class: 12,583 items\n",
        "      - Uninfected Class: 12,377 items\n",
        "    - Test Set:\n",
        "      - Parasitized Class: 1,301 items\n",
        "      - Uninfected Class: 1,301 items\n",
        "\n",
        "**Image Size**:\n",
        "- In the dataset, the images vary in size, with the largest image being 36,865 bytes (equivalent to 41 KB on disk). This particular image is a parasitized training cell and has dimensions of 364 pixels in width and 340 pixels in height.\n",
        "- Conversely, the smallest image in the dataset is a mere 1,418 bytes and measures 55 pixels in width and 40 pixels in height. It's worth noting that all images in the dataset are in PNG format and consist of three color channels (RGB).\n",
        "- To ensure consistency in analysis and processing, all these images were uniformly normalized to a resolution of 128 x 128 pixels, maintaining the three color channels. This standardization aids in facilitating efficient and consistent image analysis and classification tasks.\n",
        "\n",
        "**Data Augmentation**:\n",
        "- Among the various techniques employed, the data augmentation method involving the use of the ImageDataGenerator class yielded the most promising results. This technique was configured with several augmentation parameters to enhance the dataset, including:\n",
        "  - Rotation Range of 40 degrees\n",
        "  - Width Shift Range of 0.2\n",
        "  - Height Shift Range of 0.2\n",
        "  - Shear Range of 0.2\n",
        "  - Zoom Range of 0.2\n",
        "  - Horizontal Flip\n",
        "  - Fill Mode set to 'nearest'\n",
        "By applying these augmentation strategies, the model benefited from increased training data diversity and robustness. This, in turn, contributed to the model's improved performance, making it the preferred choice for enhancing the dataset and achieving better results in image classification tasks.\n",
        "\n",
        "**Correlations**:\n",
        "  - Parasitized Cells:\n",
        "    - Parasitized cells are characterized by the presence of one or more malaria parasites within them.\n",
        "    - These parasites, scientifically known as Plasmodium, manifest as small, dark-stained structures within the red blood cells.\n",
        "    - The presence of these parasites often leads to noticeable alterations in the shape of the infected cells.\n",
        "    - Additionally, the accumulation of malaria pigment, known as hemozoin, can result in the appearance of dark granules within parasitized cells.\n",
        "  - Uninfected Cells:\n",
        "    - In contrast, uninfected cells are devoid of malaria parasites.\n",
        "    - These uninfected cells maintain their distinctive disc-like shape and exhibit a uniform, clear appearance throughout the image analysis.\n",
        "\n",
        "\n",
        "####**Comparison of various techniques and their relative performance**:\n",
        "\n",
        "**Analysis of Base Model (Sequential CNN)**:\n",
        "- **Model Compilation:** The model was compiled using binary cross-entropy loss and the Adam optimizer, with accuracy as the evaluation metric.\n",
        "- **Architecture:** The base model is a Sequential Convolutional Neural Network (CNN) consisting of eight layers.\n",
        "  - Dropout layer with a dropout rate of 0.5, applied to the output (None, 128).\n",
        "Dense output layer with 2 units, corresponding to binary classification.\n",
        "- **Training and Validation Accuracy:** During testing, the model achieved a test accuracy of 60.79% and a test loss of 0.6596.\n",
        "- **Overfitting**:\n",
        "  - Training Accuracy: The training accuracy steadily increases over epochs, which is a typical sign of a model learning the training data very well. This suggests that the model is capable of fitting the training data closely.\n",
        "  - Validation Accuracy: However, the validation accuracy remains lower and relatively stagnant, hovering around 60%. This indicates that the model does not perform as well on data it has not seen during training. In other words, it fails to generalize to unseen examples.\n",
        "  - Gap Between Training and Validation Accuracy: There is a significant gap between the training and validation accuracy curves. When the training accuracy is substantially higher than the validation accuracy, it's a strong indicator of overfitting.\n",
        "\n",
        "---\n",
        "\n",
        "**Analysis of Model 1 (Sequential CNN)**:\n",
        "\n",
        "-  **Model Compilation**: Model 1 was compiled using binary cross-entropy loss, the Adam optimizer, and accuracy as the evaluation metric.\n",
        "- **Architecture**: It comprises 12 layers, which include convolutional layers, max-pooling layers, dense layers, and dropout layers.\n",
        "- **Techniques**: Model 1 used k-fold cross-validation and L2 regularization with a coefficient of 1e-4.\n",
        "  - Cross-Validation Results: The mean cross-validation accuracy achieved by Model 1 is 97.46%, with a low standard deviation of 0.24%. This indicates that the model performs consistently well across different validation sets.\n",
        "  - Confusion Matrix: The confusion matrix for Model 1 shows that it has a high true positive rate for both classes. It correctly identified 2159 uninfected samples and 2145 infected samples, with only 39 uninfected samples and 66 infected samples being misclassified.\n",
        "- **Training and Validation Accuracy**: During training, the model's training accuracy steadily increased from 0.9863 to 0.9978, indicating that it learned the training data effectively. However, the validation accuracy, while high (ranging from 0.9746 to 0.9796), showed some erratic behavior and stagnation. This suggests that the model might have slightly overfitted the data, as the training accuracy continued to improve while the validation accuracy did not follow the same trend.\n",
        "- **Overall**: Model 1 demonstrates strong performance, with high accuracy and robustness as indicated by cross-validation results. However, there is a slight indication of overfitting, which could be addressed with further regularization or architectural adjustments.\n",
        "\n",
        "---\n",
        "\n",
        "**Analysis of Model 2 with Batch Normalization and LeakyReLU**:\n",
        "\n",
        "- **Model Compilation**: Model 2 was compiled using binary cross-entropy loss and the Adam optimizer with a learning rate of 1e-4. The evaluation metric used was accuracy.\n",
        "- **Architecture**: It is a 14-layer sequential CNN with the incorporation of batch normalization and LeakyReLU activation functions.\n",
        "- **Callbacks**: Model 2 used three callbacks: ModelCheckpoint to save the best model based on validation loss, EarlyStopping to stop training if there is no improvement in validation loss for 10 epochs, and ReduceLROnPlateau to reduce the learning rate by half if the validation loss stagnates.\n",
        "**Test Performance**: Model 2 achieved a test loss of 0.1599 and a test accuracy of 95.05%, indicating strong generalization to unseen data. The f1-score of 0.95 for both classes suggests a balanced performance in terms of precision and recall.\n",
        "- **Training and Validation Accuracy**: During training, the model's training accuracy steadily increased from 0.7384 to 0.9961, while the validation accuracy also grew from 0.5295 to 0.9449.\n",
        "- **Overfitting**, there is some evidence of it in Model 2. The training accuracy consistently outpaces the validation accuracy, and the large gap between training and validation accuracy in the later stages of training suggests that the model has learned the training data too well, leading to overfitting. EarlyStopping and ReduceLROnPlateau callbacks help mitigate this by stopping training when validation loss stalls, but there is still room for improvement.\n",
        "\n",
        "---\n",
        "\n",
        "**Analysis of Model 3 with Data Augmentation**:\n",
        "\n",
        "- **Model Compilation**: Model 3 was compiled using binary cross-entropy loss and the Adam optimizer with a learning rate of 1e-4. The evaluation metric used was accuracy.\n",
        "- **Data Augmentation**: Data augmentation was applied using an ImageDataGenerator with various transformations such as rotation, width and height shifts, shear, zoom, horizontal flip, and nearest fill mode.\n",
        "- **Callbacks**: Model 3 used three callbacks: ModelCheckpoint to save the best model based on validation loss, EarlyStopping to stop training if there is no improvement in validation loss for 10 epochs, and ReduceLROnPlateau to reduce the learning rate by half if the validation loss stagnates.\n",
        "- **Training Process**: The training data was split into training and validation sets with a 80-20 split. Data augmentation was applied to the training set using the ImageDataGenerator. The model was trained for 20 epochs.\n",
        "- **Test Performance**: Model 3 achieved a test loss of 0.0735 and a test accuracy of 97.99%, indicating strong generalization to unseen data. The f1-score of 0.98 for both classes suggests a balanced performance in terms of precision and recall.\n",
        "- **Validation Accuracy**: The validation accuracy steadily increased from an initial value of 0.9476 to a final value of 0.9744 over the training epochs.\n",
        "- **Confusion Matrix**: The confusion matrix reveals that the model correctly classified 2643 uninfected samples as uninfected and 2758 parasitized samples as parasitized. There were 46 false positives (uninfected samples classified as parasitized) and 65 false negatives (parasitized samples classified as uninfected).\n",
        "\n",
        "**Overall, Model 3 with data augmentation performed exceptionally well, achieving high accuracy and a balanced f1-score. It also showed improvement in validation accuracy, suggesting effective generalization. The confusion matrix demonstrates that the model made relatively few misclassifications**.\n",
        "\n",
        "---\n",
        "\n",
        "**Analysis of Model 4 - Pretrained VGG16 with Additional Layers**\n",
        "\n",
        "- **Model Architecture**: Model 4 is based on the pretrained VGG16 architecture with additional layers added on top of the 'block5_pool' layer. It includes two dense layers with 516 and 256 units, respectively. The final model was compiled using the Adam optimizer and binary cross-entropy loss, with accuracy as the evaluation metric.\n",
        "- **Callbacks**: Three callbacks were utilized during training. ModelCheckpoint saved the best model based on validation loss, EarlyStopping stopped training if there was no improvement in validation loss for 10 epochs, and ReduceLROnPlateau reduced the learning rate by a factor of 0.5 if the validation loss stagnated for 3 consecutive epochs.\n",
        "- **Test Performance**: Model 4 achieved an impressive f1-score of 0.97 for both classes, indicating a strong balance between precision and recall. The validation accuracy started at 96.51% and ended at 96.85%, while the training accuracy started at 95.02% and ended at 99.98%. Training was stopped early, suggesting that the model had already converged and further training was not necessary.\n",
        "- **Confusion Matrix**: The confusion matrix shows that the model correctly classified 2596 uninfected samples as uninfected and 2752 parasitized samples as parasitized. There were 93 false positives (uninfected samples classified as parasitized) and 71 false negatives (parasitized samples classified as uninfected).\n",
        "\n",
        "**Overall, Model 4 performed exceptionally well, achieving high accuracy, an excellent f1-score, and a well-balanced confusion matrix. The early stopping indicates that the model reached its optimal performance quickly during training.**\n",
        "\n",
        "---\n",
        "\n",
        "**Analysis of Model 5: HSV CNN: Poor Performance**\n",
        "\n",
        "---\n",
        "\n",
        "**Analysis of Model 6 with HSV Images**:\n",
        "\n",
        "- **Model Architecture**: Model 6 is a Sequential CNN model with 8 layers. It was compiled using binary cross-entropy loss and the Adam optimizer with a learning rate of 0.0001. The evaluation metric used was accuracy.\n",
        "- **Class Weights**: Class weights were calculated using the 'balanced' option, and they were applied during training to account for class imbalance.\n",
        "- **Callbacks**: Model 6 used three callbacks: ModelCheckpoint to save the best model based on validation loss, EarlyStopping to stop training if there is no improvement in validation loss for 10 epochs, and ReduceLROnPlateau to reduce the learning rate by a factor of 0.2 if the validation loss stagnates for 5 consecutive epochs.\n",
        "- **Test Performance**: Model 6 achieved a test loss of 0.1852 and a test accuracy of 93.87%, indicating strong generalization to unseen data. The f1-score of 0.94 for both classes suggests a balanced performance in terms of precision and recall.\n",
        "- **Confusion Matrix**: The confusion matrix reveals that the model correctly classified 2484 uninfected samples as uninfected and 2690 parasitized samples as parasitized. There were 205 false positives (uninfected samples classified as parasitized) and 133 false negatives (parasitized samples classified as uninfected).\n",
        "- **Overall**: Model 6 performed well, achieving high accuracy and a balanced f1-score. The confusion matrix demonstrates that the model made relatively few misclassifications, considering the class imbalance.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "####**Proposal for the final solution design**:\n",
        "- What model do you propose to be adopted? Why is this the best solution to adopt?\n",
        "\n",
        "**Model 4 - Pretrained VGG16 with Additional Layers** performed the best among the models. Here are some reasons for this conclusion:\n",
        "\n",
        "High Test Performance: Model 4 achieved a high f1-score of 0.97 for both classes, indicating strong performance in terms of both precision and recall on the test dataset.\n",
        "\n",
        "Good Generalization: The model showed good generalization as seen in the consistent performance on the validation dataset, with a final validation accuracy of 96.85%.\n",
        "\n",
        "Early Stopping: The fact that training was stopped early suggests that the model converged quickly and did not require additional training epochs, indicating efficient training.\n",
        "\n",
        "Balanced Confusion Matrix: The confusion matrix showed a relatively balanced distribution of true positives and true negatives, with a low number of false positives and false negatives.\n",
        "\n",
        "Overall, Model 4 demonstrated strong performance, good generalization, and efficient training, making it the top-performing model among those analyzed.\n",
        "\n",
        "\n",
        "Model 4, the Pretrained VGG16 with Additional Layers, may have outperformed Model 3 with Data Augmentation for several reasons:\n",
        "\n",
        "- **Transfer Learning**: Model 4 utilized a pretrained VGG16 base, which is a well-established and powerful convolutional neural network (CNN) architecture pretrained on a large dataset. Transfer learning allows the model to leverage features learned from a diverse set of images, which can be highly beneficial when dealing with limited data like in medical imaging.\n",
        "\n",
        "- **Architectural Complexity**: Model 4 added additional layers on top of the VGG16 base, which increased its architectural complexity. This extra capacity may have allowed the model to learn more complex and discriminative features from the data.\n",
        "\n",
        "- **Early Stopping**: Model 4 training was stopped early, suggesting that it converged quickly and efficiently. This is a positive sign, as it indicates that the model learned from the data without overfitting.\n",
        "\n",
        "- **Consistent Validation Performance**: Model 4 showed consistent and strong performance on the validation dataset throughout training, with validation accuracy increasing from 96.51% to 96.85%. This indicates that the model was not overfitting and maintained good generalization.\n",
        "\n",
        "- **Balanced Confusion Matrix**: The confusion matrix for Model 4 showed a relatively balanced distribution of true positives and true negatives, indicating that the model was making accurate predictions for both classes.\n",
        "\n",
        "- **Use of Pretrained Weights**: The use of pretrained weights from VGG16 as initialization can help the model converge faster and find better features in the data.\n",
        "\n",
        "While Data Augmentation (Model 3) is a valuable technique to increase the effective size of the training dataset and improve model generalization, it seems that the combination of transfer learning, architectural complexity, and early stopping contributed to the superior performance of Model 4 in this specific case. However, the choice of the best model may also depend on other factors such as computational resources and the specific requirements of the application.\n",
        "\n",
        "\n"
      ]
    }
  ]
}